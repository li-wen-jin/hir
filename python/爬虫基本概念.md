#### 爬虫的常用库
1. urllib
2. re
3. requests
4. selenium：
5. chromedriver：Chrome浏览器驱动
6. phantomjs：无界面浏览器
7. lxml：提供了Xpath解析方式
8. BeautifulSoup
9. pyquery
10. pymysql
11. pymongo
12. redis
13. flask
14. django
15. jupyter

#### 什么是爬虫
请求网络并提取数据的自动化程序。

#### 爬虫基本流程
1. 发起请求
2. 获取响应内容
3. 解析内容
4. 保存数据

#### get和post请求方法的区别
不同之处：
1. 请求的参数是包含在请求的哪一部分里面
2. get可以直接跟URL进行请求，post要自己构造一个表单，点击表单提交才能构建一个post请求（比如登陆信息等）。

#### request中包含的内容
1. 请求方式：主要有GET、POST两种方式
2. 请求URL：URL是统一资源定位符，如一个网页文档，一张图片、一个视频等都可以用URL唯一来确定
3. 请求头：包含请求时的头部信息，如User-Agent、Host、Cookies等信息
4. 请求体：请求时额外携带的数据，如提交时的表单数据

#### response中包含的内容
1. 响应状态：有多种响应状态，如200代表成功、301跳转、404找不到网页、502服务器错误
2. 响应头：如内容类型、内容长度、服务器信息、设置cookie等等
3. 响应体：最主要的部分，包括了请求资源的内容，如网页html、图片二进制数据等

#### 能抓取怎样的数据
1. 网页文本：如html文档、Json格式文本等
2. 图片：获取到的是二进制文件，保存为图片格式
3. 视频：同为二进制文件，保存为视频格式即可
4. 其他：只要是能请求到的，都能获取

#### 解析方式
1. 直接处理
2. Json解析
3. 正则表达式
4. BeautifulSoup解析库
5. PyQuery解析库
6. XPath解析库

#### 为什么抓到的数据和浏览器看到的不一样

#### 怎样解决JavaScript渲染的问题
1. 分析Ajax请求
2. selenium/webdriver
3. splash
4. PyV8

#### 怎样保存数据
1. 文本
2. 关系型数据库
3. 非关系型数据库
4. 二进制文件

